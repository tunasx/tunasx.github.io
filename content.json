{"meta":{"title":"Mr.Tunas","subtitle":"blog","description":"blog","author":"Mr.Tunas","url":"https://tunasx.github.io","root":"/"},"pages":[{"title":"about","date":"2020-03-05T09:16:27.000Z","updated":"2020-03-05T09:16:27.280Z","comments":true,"path":"about/index.html","permalink":"https://tunasx.github.io/about/index.html","excerpt":"","text":""},{"title":"friends","date":"2020-03-05T10:41:39.000Z","updated":"2020-03-05T10:41:39.121Z","comments":true,"path":"friends/index.html","permalink":"https://tunasx.github.io/friends/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-03-05T09:11:34.000Z","updated":"2020-03-05T09:12:04.771Z","comments":true,"path":"categories/index.html","permalink":"https://tunasx.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-03-05T09:12:44.000Z","updated":"2020-03-05T09:12:55.130Z","comments":true,"path":"tags/index.html","permalink":"https://tunasx.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"谈一谈Golang怎么实现Web应用的平滑重启","slug":"Golang/谈一谈Golang怎么实现Web应用的平滑重启","date":"2020-03-09T16:52:30.285Z","updated":"2020-03-09T16:52:30.285Z","comments":true,"path":"2020/03/10/Golang/谈一谈Golang怎么实现Web应用的平滑重启/","link":"","permalink":"https://tunasx.github.io/2020/03/10/Golang/%E8%B0%88%E4%B8%80%E8%B0%88Golang%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0Web%E5%BA%94%E7%94%A8%E7%9A%84%E5%B9%B3%E6%BB%91%E9%87%8D%E5%90%AF/","excerpt":"","text":"背景可以说，没有什么 WEB 应用是可以永久运行一直提供服务的，中间一定会面临着服务的关闭、重启以及升级等情况，如应用切换机器部署时，需要关闭旧机器的应用。应用配置更新时，需要重启进行加载使其生效。发布新的应用功能时，需要对应用进行升级发布。同时 WEB 服务又在对外不断地提供服务，如果不加以技术手段来控制服务的关闭、重启以及升级过程，就可能造成如下几种情况： 正在处理的用户请求被断开无法响应 重启和升级过程中，服务暂时不可以，新的请求无法处理 这对于一个完善的服务来说是决不可忍受的，因此必须使用必要的手段来控制，让服务能够做到优雅的关闭和平滑重启，当然，平滑重启是必须建立在优雅关闭的基础上的，下面将针对 Golang 实现的 Web 应用来谈一谈服务的优雅关闭和平滑重启实现 实现平滑重启常用的手段 程序自己实现平滑重启 程序自己控制重启过程，需保证重启过程中，正在处理的请求不会被断开，同时新的请求可以正常响应，也就是重启过程实现零停机(Zero-Downtime) API-Gateway + CD 网关服务器 + 持续部署，通过网关层在流量调度入口处进行控制，发布升级的时候自动摘除机器，等待服务处理完现有的请求后再进行发布处理，好处是应用程序自身不需要关心如何做平滑重启 Docker + K8S 服务容器化，所有的东西均由K8S统一调度管理，是当前很火的技术方案。应用程序自身也完全不用关心如何做平滑重启 本文主要讨论程序如何自己实现平滑重启，对于其他两种方案，本人暂时了解的也不深，有兴趣的同学可以去找找相关的资料进行学习，这里就只简单说明对比下 平滑重启的过程一般情况下，应用程序自身要实现平滑重启，主要会涉及以下几个步骤的处理 应用升级的情况下，需要使用新的可执行文件替换老的可执行文件 进程启动后会注册自己的信号监听函数，允许通过 PID 给正在运行的程序发送指定的信号，如使用 SIGHUP 作为平滑重启的信号: kill -SIGHUP {pid} 老进程接收到平滑重启信号后，以子进程的方式启动新的可执行文件并继承父进程的 socket 文件，开始接受处理新的请求 子进程启动后发送特定信号给父进程，父进程进行优雅关闭 父进程处理完所有的请求后退出，子进程被 init 进程收养，继续提供服务 下面我们将分析 github 上开源的平滑重启框架 Endless 源码，来看下是怎么通过上面的步骤使用 Golang 实现平滑重启的 Endless的平滑重启实现Endless 是使用 Golang 开发的平滑重启框架，支持零停机(Zero-Downtime)重启服务 先看一下 github 上对 Endless 的特性介绍 主要有以下特性: 接入简单，对于使用原生的 net/http 包启动的服务，替换 http.ListenAndServe 和 http.ListenAndServeTLS 为 endless.ListenAndServe 和 endless.ListenAndServeTLS 即可 支持信号处理前后自定义的钩子函数 支持单个二进制文件启动多个服务 接下来看一下 Endless 是怎么实现平滑重启的 获取 Endless 包 1go get -u github.com/fvbock/endless 所有的代码实现均在项目的 endless.go 文件中， 下面看个简单的例子 12345678910111213141516171819202122232425package mainimport ( \"fmt\" \"log\" \"net/http\" \"github.com/fvbock/endless\")func main() { mux := setHandle(\"hello\") err := endless.ListenAndServe(\":8080\", mux) // 原生 net/http 包实现为 http.ListenAndServe(\":8080\", mux) if err != nil { log.Println(err) }}func setHandle(name string) http.Handler { mux := http.NewServeMux() mux.HandleFunc(\"/hello\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"hi \\n\") }) return mux} 现在从 Endless 的源码看下具体的实现endless 包共有三个导出函数 1234567// 初始化 endless 的 endlessServer 结构, endlessServer 封装了主要的函数// 默认直接调用下面的函数即可，当需要注册自定义的钩子函数时，会需要使用到该函数func NewServer(addr string, handler http.Handler) (srv *endlessServer) {...}// 启动 http 服务func ListenAndServe(addr string, handler http.Handler) error {...}// 启动 https 服务func ListenAndServeTLS(addr string, certFile string, keyFile string, handler http.Handler) error {...} 这里我们直接从 ListenAndServe 函数分析即可 123456789/*ListenAndServe listens on the TCP network address addr and then calls Servewith handler to handle requests on incoming connections. Handler is typicallynil, in which case the DefaultServeMux is used.*/func ListenAndServe(addr string, handler http.Handler) error { server := NewServer(addr, handler) return server.ListenAndServe()} NewServer 函数上面介绍了， 返回初始化后的 endlessServer 结构接下来调用的 server.ListenAndServe() 就包含了整个服务的启动流程 12345678910111213141516171819202122232425262728293031323334/*ListenAndServe listens on the TCP network address srv.Addr and then calls Serveto handle requests on incoming connections. If srv.Addr is blank, \":http\" isused.*/func (srv *endlessServer) ListenAndServe() (err error) { addr := srv.Addr if addr == \"\" { addr = \":http\" } // 注册信号处理函数 go srv.handleSignals() // 获取监听的socket文件监听器 l, err := srv.getListener(addr) if err != nil { log.Println(err) return } // 对 socket 监听器进行一层封装，实现对请求的统计计数，进程的优雅终止会用到 srv.EndlessListener = newEndlessListener(l, srv) // 判断当前启动的是否是子进程，如果是子进程，向父进程发送终止信号 if srv.isChild { syscall.Kill(syscall.Getppid(), syscall.SIGTERM) } srv.BeforeBegin(srv.Addr) // 启动服务 return srv.Serve()} 可以看到上面函数的执行涵盖了平滑重启的几个关键步骤其中 srv.handleSignals 作为信号处理函数，由单独的 goruntine 执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/*handleSignals listens for os Signals and calls any hooked in function that theuser had registered with the signal.*/func (srv *endlessServer) handleSignals() { var sig os.Signal // 拦截指定的信号， 并发送到指定通道 srv.sigChan signal.Notify( srv.sigChan, hookableSignals..., ) pid := syscall.Getpid() for { sig = 1 { env = append(env, fmt.Sprintf(`ENDLESS_SOCKET_ORDER=%s`, strings.Join(orderArgs, \",\"))) } // log.Println(files) path := os.Args[0] var args []string if len(os.Args) > 1 { args = os.Args[1:] } cmd := exec.Command(path, args...) cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr cmd.ExtraFiles = files cmd.Env = env // cmd.SysProcAttr = &syscall.SysProcAttr{ // Setsid: true, // Setctty: true, // Ctty: , // } err = cmd.Start() if err != nil { log.Fatalf(\"Restart: Failed to launch, error: %v\", err) } return} fork 函数获取父进程打开的文件、启动的参数以及环境变量，并设置标识当前为子进程的环境变量，最后以相同的命令启动子进程这里关键就是获得了父进程的 socket 文件描述符 12345678910111213for _, srvPtr := range runningServers { // introspect.PrintTypeDump(srvPtr.EndlessListener) switch srvPtr.EndlessListener.(type) { case *endlessListener: // normal listener // 返回父进程监听的 `socket` 文件描述符的一个拷贝，返回的文件和父进程的文件互相不会影响 files[socketPtrOffsetMap[srvPtr.Server.Addr]] = srvPtr.EndlessListener.(*endlessListener).File() default: // tls listener files[socketPtrOffsetMap[srvPtr.Server.Addr]] = srvPtr.tlsInnerListener.File() } orderArgs[socketPtrOffsetMap[srvPtr.Server.Addr]] = srvPtr.Server.Addr} 这样，子进程启动的时候就可以通过继承的 socket 文件描述符来替代父进程监听请求， 回来看子进程是如何继承父进程的 socket 文件的看 endlessServer 的 getListener 函数 1234567891011121314151617181920212223242526272829/*getListener either opens a new socket to listen on, or takes the acceptor socketit got passed when restarted.*/func (srv *endlessServer) getListener(laddr string) (l net.Listener, err error) { if srv.isChild { var ptrOffset uint = 0 runningServerReg.RLock() defer runningServerReg.RUnlock() if len(socketPtrOffsetMap) > 0 { ptrOffset = socketPtrOffsetMap[laddr] // log.Println(\"laddr\", laddr, \"ptr offset\", socketPtrOffsetMap[laddr]) } f := os.NewFile(uintptr(3+ptrOffset), \"\") l, err = net.FileListener(f) if err != nil { err = fmt.Errorf(\"net.FileListener error: %v\", err) return } } else { l, err = net.Listen(\"tcp\", laddr) if err != nil { err = fmt.Errorf(\"net.Listen error: %v\", err) return } } return} srv.isChild 通过环境变量 ENDLESS_CONTINUE 来判断当前是否是子进程启动， 如果是不是子进程启动就创建新的 socket 文件监听器，如果是子进程启动，就通过下面的方法 12f := os.NewFile(uintptr(3+ptrOffset), \"\")l, err = net.FileListener(f) 来继承父进程的 socket 文件返回该 socket 文件的监听器，子进程之后便可通过该监听器来替代父进程接收请求之后子进程继续执行以下代码 123456// ...if srv.isChild { syscall.Kill(syscall.Getppid(), syscall.SIGTERM)}// ...return srv.Serve() 子进程发送终止信号给父进程 启动服务 讲到这里，最后平滑重启的整个过程就只剩下父进程怎么优雅关闭了，这也是相对比较复杂的地方。要让父进程优雅关闭，就涉及下面几个步骤 关闭父进程的 socket 监听器，让父进程不再接受新的请求 等待旧连接处理完成 进程退出 关闭父进程的 socket 监听器很好处理， net 包中 Listener 接口定义的 Close 方法， 不同协议的 socket Listener 都实现了该方法来关闭监听器TCP 协议的话调用就是 TCPListener 的 Close 但怎么让父进程知道旧连接已经全部完成呢，实现也很简单，需要一个请求连接计数器，每次 Accept 请求的时候计数器加一，请求完成关闭的时候计数器就减一，当计数器为零就知道当前已经没有请求需要处理了。但 net/http 包中并没有直接提供的方法来实现上面的统计，来研究下 net/http 包中负责请求处理的方法 Serve Serve 方法定义如下 1func (srv *Server) Serve(l net.Listener) error {...} 主要负责请求处理的部分如下 1234567for { rw, e := l.Accept() ... c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx)} Accept 接收请求，然后每个请求都会单独使用一个 goruntine 来进行处理，继续看 c.serve(ctx) 发现请求处理完成后会调用 c.close()，而 c.close() 真正调用的是上面 Accept 返回的 rw 的 Close 方法， 而这两个方法都是导出的。这样，只需要重写 Serve 方法参数 net.Listener 的 Accept 方法，每次调用请求计数器加一，并重写 Accept 返回的 rw 定义的 Close 方法，进行请求统计减一，现在请求计数器可以实现了。 Endless 的实现就是这样，看下代码 123456789101112131415161718192021222324252627282930313233343536373839// srv.EndlessListener = newEndlessListener(l, srv)// 主流程函数 ListenAndServe 中的 newEndlessListener 就是对 net.Listener 的一层封装// 返回一个 endlessListener 实例func newEndlessListener(l net.Listener, srv *endlessServer) (el *endlessListener) { el = &endlessListener{ Listener: l, server: srv, } return}// endlessListener 重写了 Accept 方法 对请求统计进行加一操作，并返回一个 endlessConn 实例func (el *endlessListener) Accept() (c net.Conn, err error) { tc, err := el.Listener.(*net.TCPListener).AcceptTCP() if err != nil { return } tc.SetKeepAlive(true) // see http.tcpKeepAliveListener tc.SetKeepAlivePeriod(3 * time.Minute) // see http.tcpKeepAliveListener c = endlessConn{ Conn: tc, server: el.server, } el.server.wg.Add(1) return}// endlessConn 重写了 Close 方法， 对请求统计进行减一操作func (w endlessConn) Close() error { err := w.Conn.Close() if err == nil { w.server.wg.Done() } return err} 主流程函数 ListenAndServe 中的 newEndlessListener 就是对 net.Listener 的一层封装，返回一个 endlessListener 实例 endlessListener 重写了 Accept 方法 对请求统计进行加一操作，并返回一个 endlessConn 实例 endlessConn 重写了 Close 方法， 对请求统计进行减一操作 最后看下启动流程中的 srv.Serve() 方法 123456789func (srv *endlessServer) Serve() (err error) { defer log.Println(syscall.Getpid(), \"Serve() returning...\") srv.setState(STATE_RUNNING) err = srv.Server.Serve(srv.EndlessListener) log.Println(syscall.Getpid(), \"Waiting for connections to finish...\") srv.wg.Wait() srv.setState(STATE_TERMINATE) return} 其中 srv.Server.Serve(srv.EndlessListener) 调用的就是 net/http 包中 Server 的 Serve 方法，传参 srv.EndlessListener 即为上面分析过封装后的 net.Listener， 对请求可以进行统计。执行到 srv.Server.Serve(srv.EndlessListener) 时，如果 socket 监听器没有关闭，会进入到处理请求的循环中。所以父进程退出方法里需要关闭 socket 监听器。看下信号处理函数中的 shutdown 方法 123456789101112131415161718func (srv *endlessServer) shutdown() { if srv.getState() != STATE_RUNNING { return } srv.setState(STATE_SHUTTING_DOWN) if DefaultHammerTime >= 0 { go srv.hammerTime(DefaultHammerTime) } // disable keep-alives on existing connections srv.SetKeepAlivesEnabled(false) err := srv.EndlessListener.Close() if err != nil { log.Println(syscall.Getpid(), \"Listener.Close() error:\", err) } else { log.Println(syscall.Getpid(), srv.EndlessListener.Addr(), \"Listener closed.\") }} shutdown 方法通过调用 12srv.SetKeepAlivesEnabled(false)err := srv.EndlessListener.Close() 调用 SetKeepAlivesEnabled 关闭请求的长连接，让请求处理完就 Close 掉，保证父进程在处理完请求后能及时退出，然后关闭 socket 监听器，这时 Serve 方法退出执行 srv.wg.Wait() 等待父进程的旧请求处理完成，当请求统计计数器减到零，进程退出在 shutdown 中还发现当 DefaultHammerTime 变量不为负数时，会单独启动一个 goruntine 处理了 hammerTime 方法， 看下代码 12345678910111213141516171819202122func (srv *endlessServer) hammerTime(d time.Duration) { defer func() { // we are calling srv.wg.Done() until it panics which means we called // Done() when the counter was already at 0 and we're done. // (and thus Serve() will return and the parent will exit) if r := recover(); r != nil { log.Println(\"WaitGroup at 0\", r) } }() if srv.getState() != STATE_SHUTTING_DOWN { return } time.Sleep(d) log.Println(\"[STOP - Hammer Time] Forcefully shutting down parent\") for { if srv.getState() == STATE_TERMINATE { break } srv.wg.Done() runtime.Gosched() }} hammerTime 方法的功能就是在设置的超时时间内，如果父进程没有退出，便强制把请求统计计数减到零，让父进程强制退出。 到这里整个 Endless 的生命周期、进程的优雅关闭以及平滑重启就全部讲完，希望对大家学习如何使用 Golang 来实现平滑重启有所帮助。最后推荐几个 github 上星数比较多的， 使用 Golang 实现平滑重启的项目 本文介绍的 Endless ： https://github.com/fvbock/endless facebook 开源的： https://github.com/facebookarchive/grace overseer ： https://github.com/jpillora/overseer 总结对于 Golang 来说， 由于 Golang 提供了完善的 Socket 网络编程 net 包以及大量的提供系统调用的包，所以使用 Golang 实现平滑重启相比于其他没有提供这么完善的系统调用语言来说会相对容易一些，这也能看出 Golang 在现代网络编程中的优势。","categories":[{"name":"golang","slug":"golang","permalink":"https://tunasx.github.io/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://tunasx.github.io/tags/golang/"},{"name":"endless","slug":"endless","permalink":"https://tunasx.github.io/tags/endless/"}]},{"title":"Http状态码499、500、502、504出现原因和复现","slug":"Notes/HTTP/Http状态码499、500、502、504出现原因和复现","date":"2020-03-09T16:24:21.441Z","updated":"2020-03-09T16:24:21.441Z","comments":true,"path":"2020/03/10/Notes/HTTP/Http状态码499、500、502、504出现原因和复现/","link":"","permalink":"https://tunasx.github.io/2020/03/10/Notes/HTTP/Http%E7%8A%B6%E6%80%81%E7%A0%81499%E3%80%81500%E3%80%81502%E3%80%81504%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0%E5%92%8C%E5%A4%8D%E7%8E%B0/","excerpt":"","text":"499状态码首先 499 并不是HTTP 协议定义的状态码，而是 Nginx 自己定义的状态码，看下 Nginx 对 499 状态码的定义 1234567/* * HTTP does not define the code for the case when a client closed * the connection while we are processing its request so we introduce * own code to log such situation when a client has closed the connection * before we even try to send the HTTP header to it */#define NGX_HTTP_CLIENT_CLOSED_REQUEST 499 可以看出499状态码是用来表示客户端主动关闭连接时的响应码浏览器的默认请求超时时间一般会设置的很大， 例如 chrome 浏览器就设置为5分钟所以在浏览器中我们几乎遇不到 499 状态码, 一般见于服务之间通过 Http 方式调用时，请求方设置了请求的超时时间， 在请求超时时间内上游服务器无返回时，请求方主动关闭连接，这时上游服务器的日志将会记录一条 499 的错误日志 复现499状态码我们使用 Nginx 和 php-fpm 来复现首先我们来看几个超时时间的定义 fastcgi_read_timeout Nginx 接收上游 fastcgi 应用响应的超时时间 request_terminate_timeout 123456; The timeout for serving a single request after which the worker process will; be killed. This option should be used when the 'max_execution_time' ini option; does not stop script execution for some reason. A value of '0' means 'off'.; Available units: s(econds)(default), m(inutes), h(ours), or d(ays); Default Value: 0; request_terminate_timeout = 30 php-fpm 的 worker 进程对单个请求的处理时间， 超时将会被 KILL 通过上面的两个参数我们就可以来复现 499 错误配置如下Nginx 1234567891011121314server{ listen 80; server_name m.test.com; root /home/webroot; index index.php; location ~ / { root /home/webroot; fastcgi_pass 127.0.0.1:9000; fastcgi_read_timeout 10; fastcgi_param SCRIPT_FILENAME /home/webroot/index.php; include fastcgi_params; }} PHP 12345< ?phpsleep(5);echo 'run';error_log(\"run\", 3, \"/tmp/test.log\"); PHP-FPM 的 request_terminate_timeout 设置为 30 执行下面的请求 12# -m 3 表示超时时间设置为3scurl -I -m 3 -H \"Host:m.test.com\" 127.0.0.1 返回 1curl: (28) Operation timed out after 3001 milliseconds with 0 bytes received 看一下 Nginx 的 access 日志， 类似如下 1\"m.test.com\" \"HEAD / HTTP/1.1\" 499 0 看一下 /tmp/test.log 发现有日志， 说明 PHP 脚本会继续执行完成 500状态码 500 Internal Server Error 服务器内部错误，无法完成请求 一般就是由脚本的语法错误引起的 502状态码 502 Bad Gateway 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求 宏观上连接两个网络的设备均可成为网关， 具体到应用层 HTTP 协议, 网关就是指是转发其他服务器通信数据的服务器, 对于当前的测试环境场景， Nginx 就是网关502 并不是网关本身出现问题， 而是从上游服务器接收响应出现了问题， 例如上游服务器自身处理超时不能产生响应数据， 或者上游服务器没有按照协议响应的数据导致网关不能正常解析 复现502状态码 当 PHP-FPM 没有在运行时， 会产生 502 错误 当 PHP 脚本未在 request_terminate_timeout 设置的超时时间内完成处理时, worker 进程将被 KILL , 会产生 502 错误 1) 将 request_terminate_timeout 设置为 3 2) fastcgi_read_timeout 设置为 10 3) index.php 的休眠时间设置为 5 执行下面的请求 1curl -I -H \"Host:m.test.com\" 127.0.0.1 返回 123HTTP/1.1 502 Bad GatewayServer: openresty/1.13.6.2... 看下 Nginx 的 access 日志， 类似如下 1\"m.test.com\" \"HEAD / HTTP/1.1\" 502 644 看下 Nginx 的 error 日志， 类似如下 12020/03/08 12:56:42 [error] 155#0: *17 recv() failed (104: Connection reset by peer) while reading response header from upstream, client: 127.0.0.1, server: *.test.com, request: \"HEAD / HTTP/1.1\", upstream: \"fastcgi://127.0.0.1:9000\", host: \"m.test.com\" 看下 PHP-FPM 的错误日志 12[08-Mar-2020 12:55:21] WARNING: [pool www] child 185, script '/home/webroot/index.php' (request: \"HEAD /\") execution timed out (3.886253 sec), terminating[08-Mar-2020 12:55:21] WARNING: [pool www] child 185 exited on signal 15 (SIGTERM) after 231.236784 seconds from start 看一下 /tmp/test.log 发现并没有日志， 说明 PHP 脚本在超时后被 KILL 了 504状态码 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 表示网关没有在设置的超时时间内获得上游服务器的响应数据， 注意和 502 的区别， 502 是指上游服务器处理在自身设置的超时时间内没有处理完请求，进程被 KILL 无法正常响应数据造成的， 504 是 PHP 脚本在处理请求的某一刻已经超过了 Nginx 设置的超时时间， 但并没有超过自身设置的超时时间。Nginx 服务器由于上游服务器没能按时返回响应数据便返回 504 给客户端 复现504状态码fastcgi_read_timeout 设置为 3fastcgi_read_timeout 设置为 10index.php 的休眠时间设置为 5 执行下面的请求 1curl -I -H \"Host:m.test.com\" 127.0.0.1 返回 123HTTP/1.1 504 Gateway Time-outServer: openresty/1.13.6.2... 看下 Nginx 的 access 日志， 类似如下 1\"m.test.com\" \"HEAD / HTTP/1.1\" 504 649 看下 Nginx 的 error 日志， 类似如下 12020/03/08 13:17:08 [error] 255#0: *3 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 127.0.0.1, server: *.test.com, request: \"HEAD / HTTP/1.1\", upstream: \"fastcgi://127.0.0.1:9000\", host: \"m.test.com\" 看一下 /tmp/test.log 发现有日志， 说明 PHP 脚本会继续执行完成 总结 499 是因为请求超过了客户端设置了请求超时时间， 客户端主动关闭连接， Nginx 把这种情况定义为 499 错误进行了响应 500 基本是因为代码语法错误， 导致 CGI 应用程序执行错误， 并把错误结果通知服务器， 服务器响应 500 错误 502 是 CGI 应用程序在自身设置的请求处理时间内没有处理完请求， 无法正常响应数据给服务器， 服务器返回 502 错误 504 是 CGI 应用程序没能在服务器设置的超时时间内响应数据， 导致服务器返回 504 错误 499、502、504 均是由于超时造成的， 区别是超时是超了谁的时间， 499 是超了客户端设置的最大连接时间, 502 是超了 CGI 应用程序的最大执行时间, 504 是超了服务器设置的最大允许读取时间","categories":[{"name":"notes","slug":"notes","permalink":"https://tunasx.github.io/categories/notes/"}],"tags":[{"name":"Editing","slug":"Editing","permalink":"https://tunasx.github.io/tags/Editing/"},{"name":"Http","slug":"Http","permalink":"https://tunasx.github.io/tags/Http/"}]},{"title":"REDIS设计与实现笔记","slug":"Notes/Redis设计与实现笔记","date":"2020-03-08T13:30:24.464Z","updated":"2020-03-08T13:30:24.464Z","comments":true,"path":"2020/03/08/Notes/Redis设计与实现笔记/","link":"","permalink":"https://tunasx.github.io/2020/03/08/Notes/Redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"参考《redis设计与实现第二版》 redis版本： 2.9 数据结构和对象SDS简单动态字符串 二进制安全 除了可以保存文本文件外，还可以保存图片、音频、视频、压缩文件等二进制数据 遵循C字符串空字符结尾， 可直接重用部分C字符串库函数 长度获取 O(1) 杜绝缓存区内存溢出 减少字符串修改时的内存重分配次数 通过SDS的未使用空间，实现空间的预分配和惰性空间释放两种优化策略 1). 预分配: if sizeof(newStr) < 1MB free = sizeof(newStr) if sizeof(newStr) >= 1MB free = 1MB 2). 惰性空间释放 当需要缩短SDS的字符串长度是， 并不立即进行内存重分配来回收多余的内存， 而是使用free记录，以备将来使用 链表实现： 正常的双端链表 1234567891011121314151617181920// 链表的节点typedef struct listNode { struct listNode *prev; struct listNode *next; void *value;}listNode;// list结构持有链表，记录链表的一些属性和操作typedef struct list { listNode *head; listNode *tail; // 节点数量 unsigned long len; // 节点复制函数 void *(*dup)(void *ptr); // 节点对比函数 void (*free)(void *ptr); // 节点对比函数 int (*match)(void *ptr, void *ptr);}list; 特点 双端, 获取某个节点的前后节点时间复杂度O(1) 无环, 以NULL为终点 带表头和表尾指针，获取表头和表尾均为O(1) 带链表计数器，获取链表长度O(1) 多态 字典哈希表 1234567891011121314151617181920212223242526272829303132typedef struct dictht { dictEntry **table; unsigned long size; // 哈希表大小掩码 用户计算索引值 // 大小总是size - 1 unsigned long sizemask; // 记录哈希表的节点数量 unsigned long used;}dictht;typedef struct dictEntry { // 键 void *key; // 值 union { void *val; uint64_t u64; int64_t s64; } v; // 指向下一个哈希表节点，形成链表（解决冲突的方式） struct dictEntry *next;} dictEntry;typedef struct dict { // 类型特定函数 dictType *type; void *private; dictht ht[2]; // rehash索引 // 当rehash不在进行时，值为-1 int rehashindex;} Reids使用的hash计算算法：MurmurHash2 rehash当哈希表的负载因子到达一定程度时需要进行扩展和收缩rehash步骤 为ht[1]分配空间，大小根据要执行的操作来确定 如果是扩展操作，ht[1]的大小为第一个大于等于ht[0].used*2的2^n 如果是收缩操作，ht[1]的大小为第一个大于等于ht[0].used的2^n 将h[0]的所有键值对rehash到h[1]上面: rehash就是重新计算键的哈希值和索引值，然后将键值对放置在ht[1]哈希表的指定位置 当h[0]中的所有键值对都迁移到ht[1]后，释放h[0]，将h[1]设置为ht[0]，并在h[1]新创建一个空的哈希表，为下一次rehash做准备 哈希表的扩展和收缩时机负载因子计算： 12# 负载因子 = 哈希表已保存的节点数量 / 哈希表大小load_factor = ht[0].used / ht[0].size 下面任意条件满足会进行扩展： 服务器没有在执行BGSAVE或者BGREWRITEAOF，并且负载因子>=1 服务器正在执行BGSAVE或者BGREWRITEAOF，并且负载因子>=5当哈希表的负载因子","categories":[{"name":"notes","slug":"notes","permalink":"https://tunasx.github.io/categories/notes/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://tunasx.github.io/tags/Redis/"},{"name":"Note","slug":"Note","permalink":"https://tunasx.github.io/tags/Note/"},{"name":"Editing","slug":"Editing","permalink":"https://tunasx.github.io/tags/Editing/"}]},{"title":"Actor编程模型","slug":"编程模型/Actor编程模型","date":"2020-03-05T17:32:02.422Z","updated":"2020-03-05T17:32:02.422Z","comments":true,"path":"2020/03/06/编程模型/Actor编程模型/","link":"","permalink":"https://tunasx.github.io/2020/03/06/%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/Actor%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Actors模型(Actor model)首先是由Carl Hewitt在1973定义， 由Erlang OTP (Open Telecom Platform) 推广，其消息传递更加符合面向对象的原始意图。 Actors属于并发组件模型 ，通过组件方式定义并发编程范式的高级阶段，避免使用者直接接触多线程并发或线程池等基础概念。 传统多数流行的语言并发是基于多线程之间的共享内存，使用同步方法防止写争夺，Actors使用消息模型，每个Actors在同一时间处理最多一个消息，可以发送消息给其他Actors，保证了单独写原则 。从而巧妙避免了多线程写争夺。 Actors模型的特点是： 隔离计算实体 “Share nothing” 没有任何地方同步 异步消息传递 不可变的消息 消息模型类似mailbox / queue AKKA框架是一个实现Actors模型的Scala或Java平台，灵感来自ERlang，能更轻松地开发可扩展，实现多线程安全应用。 Actors是一个轻量级的对象，通过发送消息实现交互。每个Actors在同一时间处理最多一个消息，可以发送消息给其他Actors。在同一时间可以于一个Java虚拟机存在数以百万计的参与者，构架是一个分层的父层（管理） - 子层，其中父层监控子层的行为。还可以很容易地扩展Actor运行在集群中各个节点之间 - 无需修改一行代码。每个演员都可以有内部状态（字段/变量） ，但通信只能通过消息传递，不会有共享数据结构（计数器，队列） 。Akka框架支持两种语言Java和Scala","categories":[{"name":"code","slug":"code","permalink":"https://tunasx.github.io/categories/code/"}],"tags":[{"name":"Actor","slug":"Actor","permalink":"https://tunasx.github.io/tags/Actor/"},{"name":"Erlang","slug":"Erlang","permalink":"https://tunasx.github.io/tags/Erlang/"}]},{"title":"CSP编程模型","slug":"编程模型/CSP编程模型","date":"2020-03-05T17:31:10.846Z","updated":"2020-03-05T17:31:10.846Z","comments":true,"path":"2020/03/06/编程模型/CSP编程模型/","link":"","permalink":"https://tunasx.github.io/2020/03/06/%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/CSP%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"待写作: go","categories":[{"name":"code","slug":"code","permalink":"https://tunasx.github.io/categories/code/"}],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://tunasx.github.io/tags/CSP/"},{"name":"Golang","slug":"Golang","permalink":"https://tunasx.github.io/tags/Golang/"}]},{"title":"php-fpm 实现原理","slug":"PHP/php-fpm实现原理","date":"2020-03-05T17:26:40.318Z","updated":"2020-03-05T17:26:40.318Z","comments":true,"path":"2020/03/06/PHP/php-fpm实现原理/","link":"","permalink":"https://tunasx.github.io/2020/03/06/PHP/php-fpm%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","excerpt":"","text":"cgi是服务器与后台语言交互的协议，有了这个协议，开发者可以使用任何语言处理服务器转发过来的请求，动态地生成内容，保证了传递过来的数据是标准格式的（规定了以什么样的格式传哪些数据（URL、查询字符串、POST数据、HTTP header等等）），方便了开发者。 fastcgi首先，FastCGI会先启一个master进程，解析配置文件，初始化执行环境，然后再启动多个worker进程。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着。当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是FastCGI的对进程的管理。 php-fpmmaster进程只有一个，负责监听端口，接收来自服务器的请求，而worker进程则一般有多个（具体数量根据实际需要配置），每个进程内部都嵌入了一个PHP解释器，是PHP代码真正执行的地方从FPM接收到请求，到处理完毕，其具体的流程如下1). FPM的master进程接收到请求。2). master进程根据配置指派特定的worker进程进行请求处理，如果没有可用进程，返回错误，这也是我们配合Nginx遇到502错误比较多的原因。3). worker进程处理请求，如果超时，返回504错误。4). 请求处理结束，返回结果。 php-fpm的配置文件说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081pid = run/php-fpm.pid#pid设置，默认在安装目录中的var/run/php-fpm.pid，建议开启 error_log = log/php-fpm.log#错误日志，默认在安装目录中的var/log/php-fpm.log log_level = notice#错误级别. 可用级别为: alert（必须立即处理）, error（错误情况）, warning（警告情况）, notice（一般重要信息）, debug（调试信息）. 默认: notice. emergency_restart_threshold = 60emergency_restart_interval = 60s#表示在emergency_restart_interval所设值内出现SIGSEGV或者SIGBUS错误的php-cgi进程数如果超过 emergency_restart_threshold个，php-fpm就会优雅重启。这两个选项一般保持默认值。 process_control_timeout = 0#设置子进程接受主进程复用信号的超时时间. 可用单位: s(秒), m(分), h(小时), 或者 d(天) 默认单位: s(秒). 默认值: 0. daemonize = yes#后台执行fpm,默认值为yes，如果为了调试可以改为no。在FPM中，可以使用不同的设置来运行多个进程池。这些设置可以针对每个进程池单独设置。 listen = 127.0.0.1:9000#fpm监听端口，即nginx中php处理的地址，一般默认值即可。可用格式为: ‘ip:port’, ‘port’, ‘/path/to/unix/socket’. 每个进程池都需要设置. listen.backlog = -1#backlog数，-1表示无限制，由操作系统决定，此行注释掉就行。backlog含义参考： http://www.3gyou.cc/?p=41 listen.allowed_clients = 127.0.0.1#允许访问FastCGI进程的IP，设置any为不限制IP，如果要设置其他主机的nginx也能访问这台FPM进程，listen处要设置成本地可被访问的IP。默认值是any。每个地址是用逗号分隔. 如果没有设置或者为空，则允许任何服务器请求连接 listen.owner = wwwlisten.group = wwwlisten.mode = 0666#unix socket设置选项，如果使用tcp方式访问，这里注释即可。 user = wwwgroup = www#启动进程的帐户和组 pm = dynamic #对于专用服务器，pm可以设置为static。#如何控制子进程，选项有static和dynamic。如果选择static，则由pm.max_children指定固定的子进程数。如果选择dynamic，则由下开参数决定：pm.max_children #，子进程最大数pm.start_servers #，启动时的进程数pm.min_spare_servers #，保证空闲进程数最小值，如果空闲进程小于此值，则创建新的子进程pm.max_spare_servers #，保证空闲进程数最大值，如果空闲进程大于此值，此进行清理 pm.max_requests = 1000#设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ’0′ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0. pm.status_path = /status#FPM状态页面的网址. 如果没有设置, 则无法访问状态页面. 默认值: none. munin监控会使用到 ping.path = /ping#FPM监控页面的ping网址. 如果没有设置, 则无法访问ping页面. 该页面用于外部检测FPM是否存活并且可以响应请求. 请注意必须以斜线开头 (/)。 ping.response = pong#用于定义ping请求的返回相应. 返回为 HTTP 200 的 text/plain 格式文本. 默认值: pong. request_terminate_timeout = 0#设置单个请求的超时中止时间. 该选项可能会对php.ini设置中的’max_execution_time’因为某些特殊原因没有中止运行的脚本有用. 设置为 ’0′ 表示 ‘Off’.当经常出现502错误时可以尝试更改此选项。 request_slowlog_timeout = 10s#当一个请求该设置的超时时间后，就会将对应的PHP调用堆栈信息完整写入到慢日志中. 设置为 ’0′ 表示 ‘Off’ slowlog = log/$pool.log.slow#慢请求的记录日志,配合request_slowlog_timeout使用 rlimit_files = 1024#设置文件打开描述符的rlimit限制. 默认值: 系统定义值默认可打开句柄是1024，可使用 ulimit -n查看，ulimit -n 2048修改。 rlimit_core = 0#设置核心rlimit最大限制值. 可用值: ‘unlimited’ 、0或者正整数. 默认值: 系统定义值. chroot =#启动时的Chroot目录. 所定义的目录需要是绝对路径. 如果没有设置, 则chroot不被使用. chdir =#设置启动目录，启动时会自动Chdir到该目录. 所定义的目录需要是绝对路径. 默认值: 当前目录，或者/目录（chroot时） catch_workers_output = yes#重定向运行过程中的stdout和stderr到主要的错误日志文件中. 如果没有设置, stdout 和 stderr 将会根据FastCGI的规则被重定向到 /dev/null . 默认值: 空.","categories":[{"name":"php","slug":"php","permalink":"https://tunasx.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://tunasx.github.io/tags/php/"},{"name":"php-fpm","slug":"php-fpm","permalink":"https://tunasx.github.io/tags/php-fpm/"},{"name":"cgi","slug":"cgi","permalink":"https://tunasx.github.io/tags/cgi/"},{"name":"fast-cgi","slug":"fast-cgi","permalink":"https://tunasx.github.io/tags/fast-cgi/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-05T04:31:39.265Z","updated":"2020-03-05T04:31:39.265Z","comments":true,"path":"2020/03/05/hello-world/","link":"","permalink":"https://tunasx.github.io/2020/03/05/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}